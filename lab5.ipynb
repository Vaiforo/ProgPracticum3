{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'C:\\\\Users\\\\Arlecchino\\\\Desktop\\\\work plesk labs\\\\venv\\\\.venv\\\\Labs\\\\outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Точка входа в программу\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     67\u001b[39m output_folder = Path(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mArlecchino\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mwork plesk labs\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mvenv\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.venv\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mLabs\u001b[39m\u001b[33m\\\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Создаем папку, если она не существует\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43moutput_folder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Список результатов обработки каждого файла\u001b[39;00m\n\u001b[32m     73\u001b[39m results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\pathlib.py:1311\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1307\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1308\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m   1309\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Системе не удается найти указанный путь: 'C:\\\\Users\\\\Arlecchino\\\\Desktop\\\\work plesk labs\\\\venv\\\\.venv\\\\Labs\\\\outputs'"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd  # Библиотека для работы с данными (DataFrame)\n",
    "import os  # Модуль для взаимодействия с операционной системой\n",
    "from pathlib import Path  # Удобный способ работы с путями в разных ОС\n",
    "from sklearn.pipeline import Pipeline  # Инструмент для построения ML-конвейера\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # Для нормализации и кодирования признаков\n",
    "from sklearn.linear_model import LogisticRegression  # Модель логистической регрессии\n",
    "\n",
    "\n",
    "def run_pipeline(raw_csv: str, out_csv: str) -> dict:\n",
    "    \"\"\"\n",
    "    Функция загружает данные из CSV-файла, обучает модель и сохраняет предсказания.\n",
    "\n",
    "    raw_csv — путь к входному CSV-файлу\n",
    "    out_csv — путь к выходному файлу с предсказаниями\n",
    "    Возвращает словарь с результатами\n",
    "    \"\"\"\n",
    "\n",
    "    # Загрузка данных из CSV файла в DataFrame\n",
    "    df = pd.read_csv(raw_csv)\n",
    "\n",
    "    # Разделение на признаки (X) и целевую переменную (y)\n",
    "    X = df.drop(columns=['Collision'])  # Все столбцы, кроме 'Collision' — это признаки\n",
    "    y = df['Collision'].map({'Да': 1, 'Нет': 0})  # Целевая переменная, преобразованная в числа (1/0)\n",
    "\n",
    "    # Кодирование категориальных признаков (преобразование строковых значений в числовые)\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:  # Если тип данных — строка (категориальный признак)\n",
    "            le = LabelEncoder()  # Создаем объект LabelEncoder\n",
    "            X[col] = le.fit_transform(X[col])  # Обучаем и применяем кодировку к столбцу\n",
    "\n",
    "    # Создаем ML-конвейер (Pipeline), состоящий из двух этапов:\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Нормализация данных\n",
    "        ('lr', LogisticRegression(max_iter=1000))  # Логистическая регрессия с увеличенным количеством итераций\n",
    "    ])\n",
    "\n",
    "    # Обучаем конвейер на обучающих данных\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Делаем предсказание на тех же данных и добавляем его как новый столбец в DataFrame\n",
    "    df['pred'] = pipe.predict(X)\n",
    "\n",
    "    # Сохраняем измененный DataFrame с предсказаниями в новый CSV-файл\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Вычисляем точность модели: совпадают ли предсказанные значения с реальными\n",
    "    acc = (df['pred'] == y).mean()\n",
    "\n",
    "    # Возвращаем информацию о выполнении в виде словаря\n",
    "    return {\n",
    "        'script': 'script1',\n",
    "        'accuracy': acc,\n",
    "        'n_rows': len(df)\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция. Обрабатывает все CSV-файлы из указанной директории.\n",
    "    \"\"\"\n",
    "\n",
    "    # Путь к папке с входными CSV-файлами\n",
    "    input_folder = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\")\n",
    "\n",
    "    # Путь к папке, куда будут сохраняться выходные файлы\n",
    "    output_folder = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\outputs\")\n",
    "\n",
    "    # Создаем папку, если она не существует\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # Список результатов обработки каждого файла\n",
    "    results = []\n",
    "\n",
    "    # Перебираем все CSV-файлы в папке input_folder\n",
    "    for file_path in input_folder.glob(\"*.csv\"):\n",
    "        # Формируем имя выходного файла\n",
    "        out_file = output_folder / f\"pred_{file_path.name}\"\n",
    "\n",
    "        # Сообщаем пользователю, что файл обрабатывается\n",
    "        print(f\"Обрабатываем {file_path.name} ...\")\n",
    "\n",
    "        # Выполняем основной ML-процесс\n",
    "        res = run_pipeline(str(file_path), str(out_file))\n",
    "\n",
    "        # Сообщаем, что файл сохранён\n",
    "        print(f\"Сохранено в {out_file}\\n\")\n",
    "\n",
    "        # Добавляем результаты в список\n",
    "        results.append(res)\n",
    "\n",
    "    # Выводим сводку результатов обработки всех файлов\n",
    "    print(\"Итоги:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "\n",
    "# Точка входа в программу\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_pipeline(raw_csv: str, out_csv: str) -> dict:\n",
    "    df = pd.read_csv(raw_csv)\n",
    "\n",
    "    X = df.drop(columns=['Collision'])\n",
    "    y = df['Collision'].map({'Да': 1, 'Нет': 0})\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dt', DecisionTreeClassifier(max_depth=5))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    df['pred'] = pipe.predict(X)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    accuracy = (df['pred'] == y).mean()\n",
    "\n",
    "    return {'script': 'script2', 'accuracy': accuracy, 'n_rows': len(df)}\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_dir = Path(\n",
    "        r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\")\n",
    "    output_dir = Path(\n",
    "        r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for file_path in input_dir.glob(\"*.csv\"):\n",
    "        out_file = output_dir / f\"pred_{file_path.name}\"\n",
    "        print(f\"Processing {file_path.name} ...\")\n",
    "        res = run_pipeline(str(file_path), str(out_file))\n",
    "        print(f\"Saved predictions to {out_file}\\n\")\n",
    "        results.append(res)\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def run_pipeline(raw_csv: str, out_csv: str) -> dict:\n",
    "    df = pd.read_csv(raw_csv)\n",
    "\n",
    "    X = df.drop(columns=['Collision'])\n",
    "    y = df['Collision'].map({'Да': 1, 'Нет': 0})\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    df['pred'] = pipe.predict(X)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    accuracy = (df['pred'] == y).mean()\n",
    "\n",
    "    return {'script': 'script3', 'accuracy': accuracy, 'n_rows': len(df)}\n",
    "\n",
    "def main():\n",
    "    input_dir = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\")\n",
    "    output_dir = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for file_path in input_dir.glob(\"*.csv\"):\n",
    "        out_file = output_dir / f\"pred_{file_path.name}\"\n",
    "        print(f\"Processing {file_path.name} ...\")\n",
    "        res = run_pipeline(str(file_path), str(out_file))\n",
    "        print(f\"Saved predictions to {out_file}\\n\")\n",
    "        results.append(res)\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_pipeline(raw_csv: str, out_csv: str) -> dict:\n",
    "    df = pd.read_csv(raw_csv)\n",
    "\n",
    "    X = df.drop(columns=['Collision'])\n",
    "    y = df['Collision'].map({'Да': 1, 'Нет': 0})\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(kernel='rbf', C=1.0, gamma='scale'))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    df['pred'] = pipe.predict(X)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    accuracy = (df['pred'] == y).mean()\n",
    "\n",
    "    return {'script': 'script4', 'accuracy': accuracy, 'n_rows': len(df)}\n",
    "\n",
    "def main():\n",
    "    input_dir = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\")\n",
    "    output_dir = Path(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    for file_path in input_dir.glob(\"*.csv\"):\n",
    "        out_file = output_dir / f\"pred_{file_path.name}\"\n",
    "        print(f\"Processing {file_path.name} ...\")\n",
    "        res = run_pipeline(str(file_path), str(out_file))\n",
    "        print(f\"Saved predictions to {out_file}\\n\")\n",
    "        results.append(res)\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "def run_pipeline(raw_csv: str, out_csv: str) -> dict:\n",
    "    # Читаем CSV с твоей папки datasets_storage\n",
    "    df = pd.read_csv(raw_csv)\n",
    "\n",
    "    # Признаки — все кроме 'Collision', целевая — 'Collision', преобразуем \"Да\"/\"Нет\"\n",
    "    X = df.drop('Collision', axis=1)\n",
    "    y = df['Collision'].map({'Да':1, 'Нет':0})\n",
    "\n",
    "    # Кодируем категориальные признаки (строки)\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    # Загружаем модель из saved_models с правильным путём\n",
    "    with open(r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\saved_models\\optimized_lr_ga.pkl\", 'rb') as f:\n",
    "        best_lr = pickle.load(f)\n",
    "\n",
    "    # Создаём pipeline с масштабированием и моделью\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lr', best_lr)\n",
    "    ])\n",
    "\n",
    "    # Обучаем модель\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Добавляем предсказания\n",
    "    df['pred'] = pipe.predict(X)\n",
    "\n",
    "    # Сохраняем CSV с результатами в папку outputs\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Считаем точность\n",
    "    accuracy = (df['pred'] == y).mean()\n",
    "\n",
    "    return {'script': 'script5', 'accuracy': accuracy, 'n_rows': len(df)}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    # Путь к входному файлу в твоей папке datasets_storage\n",
    "    input_file = r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\\dataset_1_rows61_feats6.csv\"\n",
    "    # Путь к выходному файлу в папке outputs\n",
    "    output_file = r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\outputs\\script5_output.csv\"\n",
    "\n",
    "    result = run_pipeline(input_file, output_file)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_and_save_model(input_path: str, save_path: str) -> dict:\n",
    "    df = pd.read_csv(input_path)\n",
    "    X = df.drop(columns=['Collision'])\n",
    "    y = df['Collision'].map({'Да': 1, 'Нет': 0})\n",
    "\n",
    "    # Кодируем категориальные признаки\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(kernel='rbf', C=1.0, gamma='scale'))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Сохраняем только обученную модель (SVC) в pickle\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(pipe.named_steps['svc'], f)\n",
    "\n",
    "    # Вычисляем точность на обучающих данных\n",
    "    preds = pipe.predict(X)\n",
    "    accuracy = (preds == y).mean()\n",
    "\n",
    "    print(f\"Модель сохранена в {save_path}\")\n",
    "\n",
    "    # Возвращаем словарь с результатами в нужном формате\n",
    "    return {'script': 'script6', 'accuracy': accuracy, 'rows': len(df)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\datasets_storage\\dataset_1_rows61_feats6.csv\"\n",
    "    save_file = r\"C:\\Users\\Arlecchino\\Desktop\\work plesk labs\\venv\\.venv\\Labs\\saved_models\\optimized_svc_pso.pkl\"\n",
    "    results = train_and_save_model(input_file, save_file)\n",
    "    print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
